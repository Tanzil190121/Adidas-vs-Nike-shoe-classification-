{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-X82yCIb3MBd"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile(\"/content/drive/MyDrive/Classroom/archive (12).zip\",'r') as zipObj:\n",
        "  zipObj.extractall(\"/content/drive/MyDrive/DBMS\")"
      ],
      "metadata": {
        "id": "sImj3YO33SuX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_images(folder_path):\n",
        "    corrupted_images = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with Image.open(image_path) as img:\n",
        "                        img.verify()\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    corrupted_images.append(image_path)\n",
        "                    print(f\"Corrupted image: {image_path}\")\n",
        "\n",
        "    return corrupted_images\n",
        "\n",
        "folder_to_check = \"/content/drive/MyDrive/DBMS/train\"\n",
        "corrupted_images_list = check_images(folder_to_check)\n",
        "\n",
        "if len(corrupted_images_list) == 0:\n",
        "    print(\"No corrupted images found.\")\n",
        "else:\n",
        "    print(f\"Total {len(corrupted_images_list)} corrupted images found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utnM1wnK35J_",
        "outputId": "c0e9d7d8-a7b7-4d33-9ae6-247ea494fcfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No corrupted images found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_images(folder_path):\n",
        "    corrupted_images = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with Image.open(image_path) as img:\n",
        "                        img.verify()\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    corrupted_images.append(image_path)\n",
        "                    print(f\"Corrupted image: {image_path}\")\n",
        "\n",
        "    return corrupted_images\n",
        "\n",
        "folder_to_check = \"/content/drive/MyDrive/DBMS/test\"\n",
        "corrupted_images_list = check_images(folder_to_check)\n",
        "\n",
        "if len(corrupted_images_list) == 0:\n",
        "    print(\"No corrupted images found.\")\n",
        "else:\n",
        "    print(f\"Total {len(corrupted_images_list)} corrupted images found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkAm-pG34I3E",
        "outputId": "cccfb7a5-e175-454d-f8a6-3dce33c7d51f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No corrupted images found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_images(folder_path):\n",
        "    corrupted_images = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with Image.open(image_path) as img:\n",
        "                        img.verify()\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    corrupted_images.append(image_path)\n",
        "                    print(f\"Corrupted image: {image_path}\")\n",
        "\n",
        "    return corrupted_images\n",
        "\n",
        "folder_to_check = \"/content/drive/MyDrive/DBMS/validation\"\n",
        "corrupted_images_list = check_images(folder_to_check)\n",
        "\n",
        "if len(corrupted_images_list) == 0:\n",
        "    print(\"No corrupted images found.\")\n",
        "else:\n",
        "    print(f\"Total {len(corrupted_images_list)} corrupted images found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXGQhwNT4U6V",
        "outputId": "809ffe02-8cef-453a-fcf0-47c03432be4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No corrupted images found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "AZa7bv2O4bfL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "Gjp1QRff4hNB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DBMS/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    seed=1337,\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "print(\"Training dataset shape\",train_ds.cardinality())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiIG1Kxq4nlQ",
        "outputId": "1aa97ae7-6043-4485-adef-e342cb407e69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 460 files belonging to 2 classes.\n",
            "Training dataset shape tf.Tensor(15, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds=image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DBMS/test',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    seed=1337,\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        "\n",
        ")\n",
        "print(\"Testing dataset shape:\", test_ds.cardinality())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VM2tHH65Y9K",
        "outputId": "6a0495c9-0f44-47fb-92be-644b0b86475d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60 files belonging to 2 classes.\n",
            "Testing dataset shape: tf.Tensor(2, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds=image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/DBMS/validation',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    seed=1337,\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H-R4EzN5_-9",
        "outputId": "e0c90e51-3f51-443f-d179-2c3dd15aac22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 55 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Conv2D,MaxPooling2D"
      ],
      "metadata": {
        "id": "FWyk_SIv6Z4z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)\n",
        "models=Sequential(\n",
        "    [\n",
        "        Conv2D(32,(3,3),activation='relu',input_shape=(image_size[0],image_size[1],3)),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(64,(3,3),activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(128,(3,3),activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Flatten(),\n",
        "        Dense(128,activation='relu'),\n",
        "        Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Gbe1oo_b65F8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "models.fit(train_ds,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30u8NbML8hVe",
        "outputId": "b88a2f9f-f942-4093-ca47-83e42b4ecdc0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 3s 57ms/step - loss: 0.5206 - accuracy: 0.8957\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 2s 60ms/step - loss: 0.2646 - accuracy: 0.9087\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 2s 60ms/step - loss: 0.2504 - accuracy: 0.9348\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 2s 79ms/step - loss: 0.1838 - accuracy: 0.9196\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 2s 63ms/step - loss: 0.1379 - accuracy: 0.9543\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 2s 62ms/step - loss: 0.1180 - accuracy: 0.9652\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 2s 62ms/step - loss: 0.1282 - accuracy: 0.9522\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 2s 60ms/step - loss: 0.1219 - accuracy: 0.9739\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 2s 61ms/step - loss: 0.1398 - accuracy: 0.9565\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 2s 68ms/step - loss: 0.1267 - accuracy: 0.9652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cad700526b0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uf6MFNCD9S-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}